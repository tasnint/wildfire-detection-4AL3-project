The evaluation strategy employed a standard 70/15/15 train-validation-test split on a dataset containing approximately 410 images with a 61:39 fire-to-non-fire class distribution based on the ResNet18 confusion matrix totals. The training set (70\%) was used for model learning and weight optimization across the full diversity of fire and non-fire scenarios, the validation set (15\%) for hyperparameter tuning and early stopping decisions during training, and the test set (15\%) for final unbiased performance assessment. Cross-validation was not implemented due to computational constraints of training deep neural networks and the desire to ensure all three architectures (MobileNetV2, ResNet18, and EfficientNet-B0) were evaluated on identical test samples for fair comparison. While the single split approach enabled consistent comparisons and the test set size was sufficient for reliable estimates, future work should incorporate k-fold cross-validation to better quantify performance variance and ensure findings generalize across different data partitions.
The evaluation utilized a comprehensive suite of metrics that evolved significantly from the progress report stage, where accuracy and training loss were likely the primary focus. Early analysis revealed these metrics were inadequate—accuracy alone masked critical issues like ResNet18's 68\% false positive rate and EfficientNet-B0's catastrophic validation collapse from 63\% to 40\% accuracy after epoch 6. The refined evaluation framework incorporated precision to quantify false alarm rates (MobileNetV2: ~90\%, ResNet18: 32\%, EfficientNet-B0: low), recall to measure fire detection capability (MobileNetV2: ~85\%, ResNet18: 80\%, EfficientNet-B0: poor), F1-score for balanced assessment, ROC-AUC for threshold-independent performance evaluation (ResNet18: 0.629), confusion matrices for error pattern analysis, precision-recall curves (ResNet18 AP=0.737), threshold sensitivity analysis, training/validation loss convergence tracking, and inference time measurements (MobileNetV2: 180-320ms, ResNet18: 245-2880ms). These expanded metrics proved essential for understanding real-world deployment viability in safety-critical wildfire detection applications.
The metric adequacy assessment confirmed that the progress report metrics were insufficient for this application domain. Accuracy failed to distinguish between different error types—critically important in a context where missing an actual fire has catastrophic consequences (loss of life, property destruction) while false positives merely waste emergency response resources. The comprehensive evaluation revealed that while ResNet18's 80\% recall made it attractive from a pure safety perspective, its 32\% precision rendered it impractical without significant threshold adjustments. EfficientNet-B0's validation loss explosion and prediction inconsistencies indicated severe overfitting requiring complete retraining. MobileNetV2 emerged as the optimal solution with 88\% validation accuracy, balanced precision-recall performance, minimal overfitting, high-confidence predictions (0.82-0.999 range), and deployment-ready stability across all evaluation metrics.